{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AzitaKalantar/NLP-Projects/blob/main/Sentiment%20and%20Emotion%20Detector%20using%20ISEAR%20dataset/version1_Embedding_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5avqHIhDEjOF"
   },
   "source": [
    "### Building an Emotion Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcHPIZhWaMKv"
   },
   "source": [
    "Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ur482SwREnJQ",
    "outputId": "9ca1b2bf-31dc-42de-ffc6-0fea1ebe9287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeXd8pjgaRFk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('drive/My Drive/Data/ISEAR/data_train.csv')\n",
    "test_data = pd.read_csv('drive/My Drive/Data/ISEAR/data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgP7YEyJa7JO",
    "outputId": "42377a85-c1b5-4992-8ad0-5aad5267348f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion                                               Text\n",
      "0  neutral   There are tons of other paintings that I thin...\n",
      "1  sadness  Yet the dog had grown old and less capable , a...\n",
      "2     fear  When I get into the tube or the train without ...\n",
      "3     fear  This last may be a source of considerable disq...\n",
      "4    anger  She disliked the intimacy he showed towards so...\n",
      "   Emotion                                               Text\n",
      "0  sadness  I experienced this emotion when my grandfather...\n",
      "1  neutral   when I first moved in , I walked everywhere ....\n",
      "2    anger  ` Oh ! \" she bleated , her voice high and rath...\n",
      "3     fear  However , does the right hon. Gentleman recogn...\n",
      "4  sadness  My boyfriend didn't turn up after promising th...\n"
     ]
    }
   ],
   "source": [
    "train_data.columns = [\"Emotion\",\"Text\"]\n",
    "test_data.columns = [\"Emotion\",\"Text\"]\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2aj8iFRbaDY"
   },
   "source": [
    "Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "KoVXJhhTdVzT"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "OQceK_0AdyXd"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "  #make the text lower case\n",
    "  data['Text'] = data['Text'].apply(lambda a: \" \".join(a.lower() for a in a.split()))\n",
    "  #remove non-word characters (^\\w) or white space characters (\\s)\n",
    "  data['Text'] = data['Text'].apply(lambda a: \" \".join(a.replace('[^\\w\\s]','') for a in a.split()))\n",
    "  #remove stop words\n",
    "  stop = stopwords.words('english')\n",
    "  data['Text'] = data['Text'].apply(lambda a: \" \".join(a for a in a.split() if a not in stop))\n",
    "  #correct spelling\n",
    "  data['Text'] = data['Text'].apply(lambda a: str(TextBlob(a).correct()))\n",
    "  #do stemming\n",
    "  st = PorterStemmer()\n",
    "  data['Text'] =  data['Text'].apply(lambda a: \" \".join([st.stem(word) for word in a.split()]))\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Xb8spkxZbbUt",
    "outputId": "a02d10f3-7361-407c-f699-e5b7987a0c39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4ff94784-005d-4bca-9c9a-57010154a70c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ton paint think better .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>yet dog grown old less capabl , one day gilli ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>get tube train without pay ticket.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>last may sourc consider disquiet one might fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>dislik intimaci show toward , resent memori sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ff94784-005d-4bca-9c9a-57010154a70c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4ff94784-005d-4bca-9c9a-57010154a70c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4ff94784-005d-4bca-9c9a-57010154a70c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral                           ton paint think better .\n",
       "1  sadness  yet dog grown old less capabl , one day gilli ...\n",
       "2     fear                 get tube train without pay ticket.\n",
       "3     fear  last may sourc consider disquiet one might fir...\n",
       "4    anger  dislik intimaci show toward , resent memori sh..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = preprocess_data(train_data)\n",
    "test_data = preprocess_data(test_data)\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfLY5v58hcQp"
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"drive/My Drive/Data/ISEAR/pre_processsed_data_train.csv\")\n",
    "test_data.to_csv(\"drive/My Drive/Data/ISEAR/pre_processsed_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "wXLLRfNqe2tB",
    "outputId": "fb535672-0a8a-438e-c330-2eede53f2976"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6046b5f6-f846-4f3a-85aa-faac2432c232\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>experienc emot grandfath pass away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>first move , walk everywher . within week , pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>` oh ! \" belat , voic high rather indign .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>howev , right hon. gentleman recognis profound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sadness</td>\n",
       "      <td>boyfriend turn promis coming.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>sadness</td>\n",
       "      <td>sweetheart left me, rather decid break mutual ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>sadness</td>\n",
       "      <td>well , bad like differ kind move . mayb we'r d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>neutral</td>\n",
       "      <td>sure .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>sadness</td>\n",
       "      <td>’ got laid . feel sorri .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>anger</td>\n",
       "      <td>stupid peopl push rush time city.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3393 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6046b5f6-f846-4f3a-85aa-faac2432c232')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6046b5f6-f846-4f3a-85aa-faac2432c232 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6046b5f6-f846-4f3a-85aa-faac2432c232');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Emotion                                               Text\n",
       "0     sadness                experienc emot grandfath pass away.\n",
       "1     neutral  first move , walk everywher . within week , pu...\n",
       "2       anger         ` oh ! \" belat , voic high rather indign .\n",
       "3        fear  howev , right hon. gentleman recognis profound...\n",
       "4     sadness                      boyfriend turn promis coming.\n",
       "...       ...                                                ...\n",
       "3388  sadness  sweetheart left me, rather decid break mutual ...\n",
       "3389  sadness  well , bad like differ kind move . mayb we'r d...\n",
       "3390  neutral                                             sure .\n",
       "3391  sadness                          ’ got laid . feel sorri .\n",
       "3392    anger                  stupid peopl push rush time city.\n",
       "\n",
       "[3393 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('drive/My Drive/Data/ISEAR/pre_processsed_data_train.csv')\n",
    "test_data = pd.read_csv('drive/My Drive/Data/ISEAR/pre_processsed_data_test.csv')\n",
    "train_data.drop(train_data.columns[0],axis=1)\n",
    "test_data.drop(test_data.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAnDbKXNgVBj"
   },
   "source": [
    "Data Sience :\n",
    "\n",
    "Build vocabulary, vectorize and Data set and classifier classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "J0VGMZh7gUfb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "UsVKTqjpiAtq"
   },
   "outputs": [],
   "source": [
    "#the main vocabulary class job : creates a token to index and a index to token dictionary. we can access to one of each, given the other\n",
    "class Vocabulary(object):\n",
    "  def __init__(self,data=None,add_unk = True,unk_token = \"<UNK>\",add_mask = True,mask_token=\"<MASK>\"):\n",
    "    self.token_to_index = {}\n",
    "    self.index_to_token = {}\n",
    "    #mask and unk tokens are optional depending on the vocabulary and the problem\n",
    "    self.add_unk = add_unk\n",
    "    if add_unk :\n",
    "      self.unk_token = unk_token\n",
    "      self.add_token(unk_token)\n",
    "      self.unk_index = self.token_to_index[unk_token]\n",
    "    if add_mask:\n",
    "      self.add_token(mask_token)\n",
    "      self.mask_index = self.token_to_index[mask_token]\n",
    "    if data.empty == False :\n",
    "      for row in data :\n",
    "        for token in row.split():\n",
    "          self.add_token(token)\n",
    "\n",
    "  #this function gets one token and add it to the dictionary by updating both token_to_index and index_to_token      \n",
    "  def add_token(self,token):\n",
    "    if token not in self.token_to_index :\n",
    "      next_index_in_vocab = len(self.token_to_index)\n",
    "      self.token_to_index[token] = next_index_in_vocab\n",
    "      self.index_to_token[next_index_in_vocab] = token\n",
    "  # this function search for a token and returns its corresponding token, if the token is not in the vocabulary and vocabulary supports \n",
    "  # unk tokens it returns the index of unk token, otherwise it raise an error \n",
    "  def lookup_token(self,token):\n",
    "    if self.add_unk:\n",
    "      return self.token_to_index.get(token,self.unk_index)\n",
    "    else :\n",
    "      return self.token_to_index[token]\n",
    "  # this function search for a index and returns its corresponding token\n",
    "  def lookup_index(self,index):\n",
    "    return self.index_to_token[index]\n",
    "\n",
    "  # returns the legth of the vocabulary\n",
    "  def __len__(self):\n",
    "    return len(self.token_to_index)\n",
    "\n",
    "  def use_previous_token_to_index(self,token_to_index):\n",
    "    self._token_to_idx = token_to_index\n",
    "    self.index_to_token = {idx: token for token, idx in self.token_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "1fh_XyKRnG9R"
   },
   "outputs": [],
   "source": [
    "#the main job of Vectorizer class: it is responsible for converting a text (sequence of tokens) to a vectorized version of it (sequence of indexes)\n",
    "#so it can be used by neural network layers\n",
    "\n",
    "class Vectorizer(object):\n",
    "  def __init__(self,text_vocab,emotion_vocab):\n",
    "    self.text_vocab = text_vocab\n",
    "    self.emotion_vocab = emotion_vocab\n",
    "  #vector_length is usually the lentgh of the maximum text\n",
    "  #although we have textes with different lengthes but we neet  put them in a fixed-size vector and fill the remaining of the vector with mask\n",
    "  #tokens. I also return the actual length of each text\n",
    "  def vectorize(self,text,vector_length):\n",
    "    indices = [self.text_vocab.lookup_token(token) for token in text.split(' ')]\n",
    "    out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "    out_vector[:len(indices)] = indices\n",
    "    out_vector[len(indices):] = self.text_vocab.mask_index\n",
    "    return out_vector,len(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "C6GNmvfesQFZ"
   },
   "outputs": [],
   "source": [
    "#The main job of Dataset class : Dataset class inherits from Dataset class in pytorch and implements two essential funtions of it, __getitem()__\n",
    "#and __len__(), this class in being used for getting the dataset rows (vectorized version) during training and testing \n",
    "class Dataset(Dataset):\n",
    "  def __init__(self,dataframe,vectorizer):\n",
    "    self.dataframe = dataframe\n",
    "    self.vectorizer = vectorizer\n",
    "    measure_len = lambda text: len(text.split(\" \"))\n",
    "    self._max_text_length = max(map(measure_len, dataframe.Text))\n",
    "\n",
    "    # Class weights\n",
    "    class_counts = self.dataframe.Emotion.value_counts().to_dict()\n",
    "    def sort_key(item):\n",
    "        return self.vectorizer.emotion_vocab.lookup_token(item[0])\n",
    "    sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "    frequencies = [count for _, count in sorted_counts]\n",
    "    self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "\n",
    "  def __getitem__(self,index) :\n",
    "      row = self.dataframe.iloc[index]\n",
    "      vectorized_text,length_text = self.vectorizer.vectorize(row.Text, self._max_text_length)\n",
    "      target_index = self.vectorizer.emotion_vocab.lookup_token(row.Emotion)\n",
    "      #we return the vectoized version of text as x, and the index of emotion as y we also return the actual length of the text\n",
    "      return {'x_data': vectorized_text,\n",
    "              'y_target': target_index,\n",
    "              \"x_length\" : length_text\n",
    "              }\n",
    "  def __len__(self):\n",
    "    return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "nyY4eBxrDA9-"
   },
   "outputs": [],
   "source": [
    "#column gather function gets a set of outputs (of RNN cell) and returns the one after t = seeing last token in the text\n",
    "def column_gather(y_out, x_lengths):\n",
    "\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        out.append(y_out[batch_index, column_index])\n",
    "    return torch.stack(out)\n",
    "\n",
    "#main job of classifier class : it inherits from the Module class in pytorch and implements a forward function, it builds the structure of the\n",
    "#neural network model and is being used for doing forward pass in training process\n",
    "class EmotionClassifier(nn.Module):\n",
    "  def __init__(self,num_classes, text_vocab_size,embedding_size,rnn_hidden_size,pretrained_embeddings=None,padding_idx=0,dropout_p=0.5):\n",
    "    super(EmotionClassifier, self).__init__()\n",
    "    if pretrained_embeddings is None :\n",
    "      # I created an embedding layer to convert each token to a an ambedded vector. Embedded vecores are being created and tuned during the\n",
    "      # training process. embedding_dim is an arbitary size that we want to have for each embedded token.\n",
    "      self.word_emb = nn.Embedding(num_embeddings=text_vocab_size,\n",
    "                                      embedding_dim=embedding_size,\n",
    "                                      padding_idx=padding_idx)\n",
    "    else :\n",
    "      pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float() \n",
    "      self.word_emb = nn.Embedding(num_embeddings=text_vocab_size,\n",
    "                                embedding_dim=embedding_size,\n",
    "                                padding_idx=padding_idx,\n",
    "                                _weight=pretrained_embeddings)\n",
    "    #GRU is a sequential nerural network layer which generates outputs by using a sequense of inputes and its hidden layer. at each time step \n",
    "    #(seeing one token), it also updates its hidden layer. hidden_size is an arbitary output size for GRU layer\n",
    "    self.rnn = nn.GRU(input_size=embedding_size,\n",
    "                          hidden_size=rnn_hidden_size,\n",
    "                          batch_first=True)\n",
    "\n",
    "    self.fc1 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                      out_features=rnn_hidden_size)\n",
    "    self.fc2 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                      out_features=num_classes)\n",
    "  \n",
    "  def forward(self,x_in,apply_softmax=False,x_lengths=None):\n",
    "        # we tranfer indexes to embedded vectores\n",
    "        x_embedded = self.word_emb(x_in)\n",
    "        # we use our rnn layer and get a sequence of outputs, each one corresponding to one time step\n",
    "        y_out, _ = self.rnn(x_embedded)\n",
    "\n",
    "        #if x_lengths is providede we select the output of rnn cell which was provided after seeing the last token in the test\n",
    "        if x_lengths is not None:\n",
    "            y_out = column_gather(y_out, x_lengths)\n",
    "        #otherwise we select the last ouput (real tokens + mask tokens)\n",
    "        else:\n",
    "            y_out = y_out[:, -1, :]\n",
    "\n",
    "        y_out = F.relu(self.fc1(F.dropout(y_out, 0.5)))\n",
    "        y_out = self.fc2(F.dropout(y_out, 0.5))\n",
    "        #soft mask is better to be used just for testing and not during training proceess (makes some mathmatical difficulities with our \n",
    "        #cross entropy loss function)\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "\n",
    "        return y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaJhgigEIiIT"
   },
   "source": [
    "Initializing and Tranining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "KhJgSfROIsLX"
   },
   "outputs": [],
   "source": [
    "#a function for loading the pretained embedings (glove embeddings is this case)\n",
    "def load_glove_from_file(glove_filepath):\n",
    "\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(glove_filepath, \"r\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \") # each line: word num1 num2 ...\n",
    "            word_to_index[line[0]] = index # word = line[0]\n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, np.stack(embeddings)\n",
    "#this function uses the function above and creates an embedding matrix for the words that we have in our vocabulary\n",
    "#this matrix is being used as weights for our Embeddings layer in the classifier\n",
    "def make_embedding_matrix(glove_filepath, words):\n",
    "\n",
    "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
    "    embedding_size = glove_embeddings.shape[1]\n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            #if there is a word in out vocabulary which is not in the glove dataset, we use a uniformely distributed data as the embedding\n",
    "            embedding_i = torch.ones(1, embedding_size)\n",
    "            torch.nn.init.xavier_uniform_(embedding_i)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "    return final_embeddings\n",
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "batch_size=128\n",
    "learning_rate=0.001\n",
    "num_epochs=15\n",
    "seed=1376\n",
    "embedding_size=100\n",
    "rnn_hidden_size=64\n",
    "val_ratio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9593aPtoI2VF",
    "outputId": "50f166fb-57bd-435d-d54a-f7b2bc432af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False, device : cpu\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    cuda = False\n",
    "    device = torch.device(\"cpu\")\n",
    "else :\n",
    "    cuda = True\n",
    "    device = torch.device(\"cuda\")\n",
    "print(\"Using CUDA: {}, device : {}\".format(cuda,device))\n",
    "set_seed_everywhere(seed,cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "yRciQdvWAsZR"
   },
   "outputs": [],
   "source": [
    "#splitting the training data into train and validation data\n",
    "val_ratio = 0.15\n",
    "val_data = pd.DataFrame(columns = [\"Text\",\"Emotion\"])\n",
    "for label in train_data.Emotion.unique():\n",
    "      val_df  = train_data[train_data[\"Emotion\"] == label].sample(frac = val_ratio)\n",
    "      val_data =pd.concat([val_data, val_df], axis=0)\n",
    "\n",
    "\n",
    "train_data = train_data[~train_data.loc[:,[\"Text\",\"Emotion\"]].index.isin(val_data.loc[:,[\"Text\",\"Emotion\"]].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go-JWwBxKVzS"
   },
   "source": [
    "Loading dataset and creating vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "ieyfjU-VKWeP"
   },
   "outputs": [],
   "source": [
    "# we should build the vocabularies and the vectorizer just using our trainig data\n",
    "emotion_vacob = Vocabulary(train_data.Emotion,add_unk = False,add_mask = False)\n",
    "text_vocab = Vocabulary(train_data.Text,add_unk = True) \n",
    "vectorizer = Vectorizer(text_vocab,emotion_vacob)\n",
    "#making train, validation and test  validation datastes\n",
    "val_dataset = Dataset(val_data,vectorizer)\n",
    "train_dataset = Dataset(train_data,vectorizer)\n",
    "test_dataset = Dataset(test_data,vectorizer)\n",
    "#we use a pretained embeddings dataset (glove) as the initial weights of our Embedding layer in the classifier\n",
    "words = text_vocab.token_to_index.keys()\n",
    "embeddings = make_embedding_matrix(glove_filepath=\"/content/drive/My Drive/Data/ISEAR/glove.6B.100d.txt\", words=words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "Afz6stu0lnGK"
   },
   "outputs": [],
   "source": [
    "classifier = EmotionClassifier(text_vocab_size=len(text_vocab),num_classes=len(emotion_vacob),embedding_size=embedding_size,\n",
    "                               rnn_hidden_size=rnn_hidden_size,pretrained_embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "sLOfWGTromru"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "SoKNxBQkEehs"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(train_dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "ZcJcOeo0H0c8"
   },
   "outputs": [],
   "source": [
    "train_loss= []\n",
    "train_acc = []\n",
    "val_loss= []\n",
    "val_acc = []\n",
    "smalles_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "  running_loss = 0.0\n",
    "  running_acc = 0.0\n",
    "  classifier.train()\n",
    "  for batch_index, batch_dict in enumerate(train_dataloader):\n",
    "    #zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #compute the output\n",
    "    y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                        x_lengths=batch_dict['x_length'])\n",
    "\n",
    "    #compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "\n",
    "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "    #use loss to produce gradients\n",
    "    loss.backward()\n",
    "\n",
    "    #use optimizer to take gradient step\n",
    "    optimizer.step()\n",
    "    \n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "  train_loss.append(running_loss)\n",
    "  train_acc.append(running_acc)\n",
    "\n",
    "  running_loss = 0.\n",
    "  running_acc = 0.\n",
    "  classifier.eval()\n",
    "  for batch_index, batch_dict in enumerate(val_dataloader):\n",
    "\n",
    "    #compute the output\n",
    "    y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                        x_lengths=batch_dict['x_length'])\n",
    "\n",
    "    #compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "\n",
    "    running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "    \n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "  \n",
    "  val_loss.append(running_loss)\n",
    "  val_acc.append(running_acc)\n",
    "  #saving the best model we have so far\n",
    "  if running_loss < smalles_loss :\n",
    "    torch.save(classifier.state_dict(),\"drive/My Drive/Data/ISEAR/model\")\n",
    "    smalles_loss = running_loss\n",
    "\n",
    "  scheduler.step(running_loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "wQXzGtUyHfC4",
    "outputId": "6f6e2547-43d0-4bf5-fcf8-ce7859a80c14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot1, = plt.plot(train_loss)\n",
    "plot2, = plt.plot(val_loss)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([plot1,plot2],[\"Train\", \"Validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jS3jFM6kRD8a",
    "outputId": "247bb404-fb76-4b4a-c721-65c2afa732da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we load the best model we had during training process\n",
    "classifier.load_state_dict(torch.load(\"drive/My Drive/Data/ISEAR/model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "k2pYE00ZmMvW"
   },
   "outputs": [],
   "source": [
    "test_running_loss = 0.0\n",
    "test_running_acc = 0.0\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(test_dataloader):\n",
    "  # compute the output\n",
    "  y_pred =  classifier(batch_dict['x_data'],\n",
    "                        x_lengths=batch_dict['x_length'])\n",
    "  \n",
    "  # compute the loss\n",
    "  loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "  loss_t = loss.item()\n",
    "  test_running_loss += (loss_t - test_running_loss) / (batch_index + 1)\n",
    "\n",
    "  # compute the accuracy\n",
    "  acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "  test_running_acc += (acc_t - test_running_acc) / (batch_index + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ib2jYidsISEn",
    "outputId": "db74ad62-22d6-4bb9-9e0e-8cd6a4e08793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : 1.0512788868867433, test accuracy : 63.28125\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss : {}, test accuracy : {}\".format(test_running_loss,test_running_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zutw4LtkKRTY"
   },
   "source": [
    "To be able to use the trained model later, it is important to save the text vocabulary we built from the training data, it will be used for generating vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "Y5pZm3FsKjZA"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "vocabs = {'text_vocab': text_vocab.token_to_index}\n",
    "with open(\"drive/My Drive/Data/ISEAR/vocabs.json\", \"w\") as fp:\n",
    "  json.dump(vocabs, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0AYxe5CiRjy"
   },
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "qNzgCIt0dP5R"
   },
   "outputs": [],
   "source": [
    "def predict_emotion(Text, classifier, vectorizer, max_length):\n",
    "    vectorized_text,_ = vectorizer.vectorize(Text, vector_length=max_length)\n",
    "    vectorized_text = torch.tensor([vectorized_text])\n",
    "    result = classifier(vectorized_text, apply_softmax=True)\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    predicted_emotion = vectorizer.emotion_vocab.lookup_index(indices.item())\n",
    "\n",
    "    print({'Emotion': predicted_emotion, 'probability': probability_values.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJlv-KD8ePYv",
    "outputId": "a8340623-721a-4da6-8575-3655b0b71103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Emotion': 'joy', 'probability': 0.3964931070804596}\n"
     ]
    }
   ],
   "source": [
    "predict_emotion(\"I feel good\",classifier,vectorizer,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p50wRPoleu0-",
    "outputId": "cccb0c60-f93b-40e3-dc15-0ec783eacc7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Emotion': 'sadness', 'probability': 0.5235527157783508}\n"
     ]
    }
   ],
   "source": [
    "predict_emotion(\"I feel bad\",classifier,vectorizer,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzE6qhw4iInG",
    "outputId": "7db5f76c-b14b-415b-8a08-3d821bc458d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Emotion': 'fear', 'probability': 0.32802513241767883}\n"
     ]
    }
   ],
   "source": [
    "predict_emotion(\"I feel nervous\",classifier,vectorizer,3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6hbUo+eylF4TYLq+TgjnQ",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
